{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Google’s Lift Measurement is a tool which offers a convenient, easy to set-up and almost real-time approach to measure the effect that our campaigns have on some of the most strategic marketing metrics, specifically, ones related to brand management.\n",
    "\n",
    "Having said this, there’s some key missing pieces of information that we as marketeers would normally want to have, as it is provided in most studies.\n",
    "\n",
    "\n",
    "## Google Brand Lift\n",
    "<b>About Lift Measurement</b>\n",
    "\n",
    "Lift Measurement is a tool within <a href=\"https://ads.google.com/\" target=\"_blank\">Google Ads Platform</a> that’s capable of measuring how your ads impact people’s perception of your brand. These measures are extremely useful for us marketeers, since allows us to evaluate how a specific marketing campaign performs in terms of well-known key marketing metrics such as Brand Awareness, Recall and Consideration rather than the usual Digital Marketing metrics like clicks, impressions, frequency and reach.\n",
    "\n",
    "Once enabled, the tool allow us to measure up to 3 different metrics which includes the already mentioned plus Favoravility and Purchase Intent. Additionally, like in traditional consumer tests, the tool requires that we provide some alternative brands from the category which typically includes direct competitors.\n",
    "\n",
    "In terms of costs, even though it’s advertised as free, in practice Google ask for a minimum investment in terms of ad spend of the campaign being tested which in case of YouTube Ads varies based on location but for videos anywhere else within their networks is USD $15,000.\n",
    "\n",
    "<b>How it works</b>\n",
    "\n",
    "Once the campaign is set up, metrics are selected and brands from category (typically competitors) are defined, you’ll be given a preliminary minimum budget which one can assume is as a function of the statistical power.\n",
    "\n",
    "Eventually when campaigns are running and ads are being served, the tool will randomly generate a test and control group. Specifically, groups will be generated based on the following criteria:\n",
    "\n",
    "- <b>Test group:</b> People who have seen our ads\n",
    "- <b>Control group:</b> People who were eligible by our campaign segmentation, but didn’t saw our ads.\n",
    "\n",
    "Surveys from both groups will be gathered and different metrics such as Brand Lift will be computed and shown in the dashboard as soon a “detectable” result is found, which Google defines this to be as a Lift >2.0%.\n",
    "\n",
    "<b>Results</b>\n",
    "\n",
    "Once enough survey responses are collected the tool will present its results in terms of expected values and their corresponding (confidence) intervals in the form of the following metrics:\n",
    "\n",
    "- <b>Baseline PRR:</b> Percent of people in the control group who selected our brand as their preference amongst all other provided brands.\n",
    "- <b>Exposed PRR:</b> Percent of people in the test group who selected our brand as their preference amongst all other provided brands.\n",
    "- <b>Absolute Brand Lift:</b> Difference in PRR between Test and Control groups.\n",
    "- <b>Relative Brand Lift:</b> Increase of Baseline PRR due to the tested campaign (Absolute Brand Lift / Baseline PRR).\n",
    "- <b>Total Survey Responses:</b> Number of total surveys (Test + Control).\n",
    "\n",
    "Other metrics engineered from the above, such as as Cost Per Lifted User, Exposed to Ads, Not Exposed to Ads are also included in the report.\n",
    "\n",
    "<i>* PRR: Positive Response Rate</i>\n",
    "\n",
    "## Missing Information\n",
    "To understand if a small observed lift might be due to just random chance, generate new intervals according to our preferences and generally speaking better communicating the results within our company we would need information that’s currently not being provided in a straight forward way.\n",
    "\n",
    "Additionally this information might shed some light into a deeper understanding as for why we need to invest the minimum budget that’s being asked, which in many cases is done for the sole purpose of this study.\n",
    "\n",
    "In particular:\n",
    "\n",
    "- <b>Level of significance:</b> Even though numeric confidence intervals are included for every metric, the actual confidence level in terms of percentages is not given nor it is commonly addressed within the documentation. So far, I've been able to locate some official information that states that's \"usually around 90%\" </i><a href=\"https://support.google.com/displayvideo/answer/9724932?hl=en\" target=\"_blank\">[ref]</a> but whether this is one or two-tailed is unclear.\n",
    "- <b>P-Value:</b> This would allow us to make a fast hypothesis check for different levels of confidence we might use.\n",
    "\n",
    "Lastly, even through \"Total survey responses\" is clearly informed both in summary and within the report itself, actual sample size of test and control groups is not displayed by default in the summary page nor it is available anywhere else within the report itself, limiting our ability to conduct our own statistical tests for Age, Gender, Campaign and Video related results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the missing information\n",
    "In order to find the missing information we need to perform a heuristic search of all possible combinations of Confidence Levels and Sample Sizes and then compare those results to check which has the better approximation to the results provided by Google.\n",
    "\n",
    "In order to avoid a brute-forcing method which is time and resource consuming a custom algorithm was built that will try to learn 2 parameters: Baseline PRR and Interval as defined by the difference between expected Upper and Lower Absolute Brand Lift values.\n",
    "\n",
    "\n",
    "## Custom Optimization Algorithm\n",
    "A custom optimization algorithm was built which will allow us to obtain a good approximation of:\n",
    "- Level of significance.\n",
    "- Sample size of both test and control groups.\n",
    "- Standard Error.\n",
    "- p-Value\n",
    "\n",
    "This information will allow us to conduct our own statistical tests, which is a stepping stone in generating confidence intervals that suit our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm\n",
    "LiftUncover <-function(Surveys,p1,p2,UpperInterval,LowerInterval,staticLR=.1,maxIterations=10000,pValue=NULL) {\n",
    "  \n",
    "  # Target parameter initialization\n",
    "  n1 <- Surveys*0.5\n",
    "  if(is.null(pValue)) {\n",
    "    zScore <- 1\n",
    "  } else {\n",
    "      # False positive rate is provided. We dont need to predict Standard Score.\n",
    "      zScore <- round(abs(qnorm(pValue/2)),2)\n",
    "  }\n",
    "  \n",
    "  # Transform to percentages.\n",
    "  RealInterval <- ((UpperInterval)-(LowerInterval))/200\n",
    "  p1 <- p1/100\n",
    "  p2 <- p2/100\n",
    "  \n",
    "  # For ADAGRAD\n",
    "  gradientsN1 <- c()\n",
    "  gradientszScore <- c()\n",
    "  \n",
    "  # Temporal variables.\n",
    "  temp <- Inf\n",
    "  \n",
    "  # Iteration Loop!\n",
    "  for(i in 1:maxIterations) {\n",
    "    \n",
    "    # n2 calculation\n",
    "    n2 <- Surveys-n1\n",
    "    \n",
    "    # We compute a predicted interval for given values and parameters\n",
    "    PredictedInterval <- (zScore*sqrt(((p1 * n1 + p2 * (Surveys - n1)) / (Surveys)) * ( 1 - ((p1 * n1 + p2 * (Surveys - n1)) / (Surveys)) ) * ((1/n1) + (1/(Surveys - n1))) ) )\n",
    "    \n",
    "    # We generate a differentiable cost function\n",
    "    Cost <- (RealInterval-PredictedInterval)^2\n",
    "    \n",
    "    # Print current Cost every 1000 iterations\n",
    "    if(i %% 1000==0) {\n",
    "      print(paste(\"Iteration\",i,\":\",sqrt(Cost)))\n",
    "    }\n",
    "    \n",
    "    # N1 Gradient\n",
    "    dn1dCost <- -(100 * (zScore * ((1 - (n1 * p1 + p2 * (Surveys - n1))/Surveys) * (1/(Surveys - n1)^2 - 1/n1^2) * (n1 * p1 + p2 * (Surveys - n1)) + (1 - 2 * ((n1 * p1 + p2 * (Surveys - n1))/Surveys)) * (1/(Surveys - n1) + 1/n1) * (p1 - p2)) * (RealInterval - zScore * sqrt((1 - (n1 * p1 + p2 * (Surveys - n1))/Surveys) * (1/(Surveys - n1) + 1/n1) * (n1 * p1 + p2 * (Surveys - n1))/Surveys))/ (Surveys * sqrt((1 - (n1 * p1 + p2 * (Surveys - n1))/Surveys) * (1/(Surveys - n1) + 1/n1) * (n1 * p1 + p2 * (Surveys - n1))/Surveys))))\n",
    "    \n",
    "    # Sample size (n1) gradient adjustment\n",
    "    gradientsN1 <- rbind(gradientsN1,dn1dCost)\n",
    "    sumgradientsN1 <- sum(gradientsN1^2) \n",
    "    learningRateN1 <- staticLR / sqrt(sumgradientsN1 + 10^-8)\n",
    "    \n",
    "    # Sample size Parameter update\n",
    "    n1 <- n1 - (learningRateN1  * dn1dCost )\n",
    "    \n",
    "    if(is.null(pValue))  {\n",
    "      # zScore Gradient\n",
    "      dzScoredCost <- -(200 * ((RealInterval - zScore * sqrt((1 - (n1 * p1 + p2 * (Surveys - n1))/Surveys) * (1/(Surveys - n1) + 1/n1) * (n1 * p1 + p2 * (Surveys - n1))/Surveys)) * sqrt((1 - (n1 * p1 + p2 * (Surveys - n1))/Surveys) * (1/(Surveys - n1) + 1/n1) * (n1 * p1 + p2 * (Surveys - n1))/Surveys)))\n",
    "      \n",
    "      # Standard Score gradient adjustment\n",
    "      gradientszScore <- rbind(gradientszScore,dzScoredCost)\n",
    "      sumGradientszScore  <- sum(gradientszScore^2) \n",
    "      learningRatezScore <- staticLR / sqrt(sumGradientszScore + 10^-8)\n",
    "      \n",
    "      # zScore Parameter update\n",
    "      zScore <- zScore - (learningRatezScore   * dzScoredCost)\n",
    "      \n",
    "    }\n",
    "    \n",
    "    # Results\n",
    "    if(sqrt(Cost) >= temp || i == maxIterations) {\n",
    "      cat(paste(\"Values found after\",i,\"iterations\\n\"))\n",
    "      output <- list()\n",
    "      if(is.null(pValue)) {\n",
    "          \n",
    "        # We calculate false positive rate\n",
    "        errorRate <- round(2*pnorm(-abs(zScore)),2)\n",
    "        cat(paste(\"   - Predicted Type I Error:\",errorRate,\"\\n\"))\n",
    "        \n",
    "        # Adjustment to most likely error selected by Google\n",
    "        # Difference might be due to rounded intervals provided\n",
    "        DefaultErrors <- c(.01,.05,.1,.2,.25,.3,.45)\n",
    "        Distance <- abs(DefaultErrors-errorRate)\n",
    "        likelyError <- DefaultErrors[which(Distance==min(Distance))]\n",
    "        cat(paste(\"   - Most likely Type I Error:\",likelyError,\"\\n\"))\n",
    "        cat(paste(\"   - Most likely Level of Significance: \",(1-likelyError)*100,\"% (two tailed)\\n\",sep=\"\"))\n",
    "          \n",
    "        # Output values\n",
    "        output$predicted <- errorRate\n",
    "        output$likely <- likelyError\n",
    "\n",
    "      } else {\n",
    "          \n",
    "        # Standard Error\n",
    "        standardError = sqrt((1 - (n1 * p1 + n2 * p2)/Surveys) * (1/n1 + 1/n2) * (n1 * p1 + n2 * p2)/Surveys)\n",
    "        pValue <- round(2*pnorm(-abs((p1 - p2) / standardError)),6)\n",
    "          \n",
    "        cat(paste(\"   - Sample size 1 (n1):\",round(n1),\"surveys\\n\"))\n",
    "        cat(paste(\"   - Sample size 2 (n2):\",Surveys-round(n1),\"surveys\\n\"))\n",
    "        cat(paste(\"   - Standard Error:\",standardError,\"\\n\"))\n",
    "        cat(paste(\"   - p-value:\",pValue,\"\\n\"))\n",
    "        \n",
    "      \n",
    "        # Output values\n",
    "        output$n1 <- round(n1)\n",
    "        output$n2 <- Surveys-round(n1)\n",
    "        output$standardError <- standardError\n",
    "        output$pValue <- pValue\n",
    "      }\n",
    "      \n",
    "      break();\n",
    "    }\n",
    "    temp <- round(sqrt(Cost),13)\n",
    "    \n",
    "  }\n",
    "return(output)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm in use\n",
    "\n",
    "### Outputs from Lift Measurement Tool\n",
    "Inputs provided by Google Brand Lift Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExposedPRR <- 40.22\n",
    "BaselinePRR <- 37.67\n",
    "TotalSurveys <- 5623\n",
    "LiftUpperInterval <- 4.3\n",
    "LiftLowerInterval <- 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Lift: 2.55%"
     ]
    }
   ],
   "source": [
    "# Some metrics\n",
    "Lift <- (ExposedPRR-BaselinePRR)/100\n",
    "cat(\"Expected Lift: \",Lift*100,\"%\",sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Lift (already known by Lift Measurement report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Level Calculation\n",
    "We will try to obtain the confidence level used by Google in the report generated by the tool.\n",
    "\n",
    "<font color='darkred'><b>Note:</b> We have two outputs (Predicted and Most Likely). This is because Google provides us approximate (rounded) values, which affects this calculation.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values found after 98 iterations\n",
      "   - Predicted Type I Error: 0.19 \n",
      "   - Most likely Type I Error: 0.2 \n",
      "   - Most likely Level of Significance: 80% (two tailed)\n"
     ]
    }
   ],
   "source": [
    "ErrorPrediction <- LiftUncover(TotalSurveys,ExposedPRR,BaselinePRR,LiftUpperInterval,LiftLowerInterval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Sizes, Standard Error and p-Values\n",
    "Values are calculated using the \"Most likely Type I Error\" error calculated above.\n",
    "Note that these values will be the best approximation possible to given parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values found after 86 iterations\n",
      "   - Sample size 1 (n1): 3366 surveys\n",
      "   - Sample size 2 (n2): 2257 surveys\n",
      "   - Standard Error: 0.0132812499999766 \n",
      "   - p-value: 0.054858 \n"
     ]
    }
   ],
   "source": [
    "likelyError <- ErrorPrediction$likely\n",
    "samplePrediction <- LiftUncover(TotalSurveys,ExposedPRR,BaselinePRR,LiftUpperInterval,LiftLowerInterval,staticLR=100000,pValue=likelyError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the results above, we obtained a <b>p-Value of 0.054858</b> so as we will later confirm, we can anticipate <font color='darkred'>results will not be significant for intervals of 95% or more</font>, though it's pretty close at 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Found the missing pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 <- samplePrediction$n1\n",
    "n2 <- samplePrediction$n2\n",
    "standardError <- samplePrediction$standardError\n",
    "pValue <- samplePrediction$pValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Brand Lift Values\n",
    "Now we can calculate the original report with all missing information included.<br>\n",
    "This should be a good approximation to the actual values provided by Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% confidence interval:\n",
      "0.85%  -  4.25%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original detected Brand Lift Error\n",
    "Error <- likelyError\n",
    "\n",
    "# Brand Lift confidence Interval\n",
    "ConfidenceInterval <- (1-Error)*100\n",
    "zScore <- round(abs(qnorm(Error/2)),2)\n",
    "cat(paste(ConfidenceInterval,\"% confidence interval:\\n\",sep=\"\"))\n",
    "Upper <- round(Lift + (zScore*standardError),5)*100\n",
    "Lower <- round(Lift - (zScore*standardError),5)*100\n",
    "cat(paste(Lower,\"%  -  \",Upper,\"%\\n\\n\",sep=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval at 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90% confidence interval:\n",
      "0.372%  -  4.728%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10 percent probability of type 1 error\n",
    "Error <- 0.1\n",
    "\n",
    "# Brand Lift confidence Interval\n",
    "ConfidenceInterval <- (1-Error)*100\n",
    "zScore <- round(abs(qnorm(Error/2)),2)\n",
    "cat(paste(ConfidenceInterval,\"% confidence interval:\\n\",sep=\"\"))\n",
    "Upper <- round(Lift + (zScore*standardError),5)*100\n",
    "Lower <- round(Lift - (zScore*standardError),5)*100\n",
    "cat(paste(Lower,\"%  -  \",Upper,\"%\\n\\n\",sep=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval at 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval:\n",
      "-0.053%  -  5.153%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 percent probability of type 1 error\n",
    "Error <- 0.05\n",
    "\n",
    "# Brand Lift confidence Interval\n",
    "ConfidenceInterval <- (1-Error)*100\n",
    "zScore <- round(abs(qnorm(Error/2)),2)\n",
    "cat(paste(ConfidenceInterval,\"% confidence interval:\\n\",sep=\"\"))\n",
    "Upper <- round(Lift + (zScore*standardError),5)*100\n",
    "Lower <- round(Lift - (zScore*standardError),5)*100\n",
    "cat(paste(Lower,\"%  -  \",Upper,\"%\\n\\n\",sep=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkred'>As predicted above, at this point, expected interval includes the chance of lift being zero which is consistent with our p-value found before.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval at 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% confidence interval:\n",
      "-0.827%  -  6.027%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 percent probability of type 1 error\n",
    "Error <- 0.01\n",
    "\n",
    "# Brand Lift confidence Interval\n",
    "ConfidenceInterval <- (1-Error)*100\n",
    "zScore <- round(abs(qnorm(Error/2)),2)\n",
    "cat(paste(ConfidenceInterval,\"% confidence interval:\\n\",sep=\"\"))\n",
    "Upper <- round(Lift + (zScore*standardError),5)*100\n",
    "Lower <- round(Lift - (zScore*standardError),5)*100\n",
    "cat(paste(Lower,\"%  -  \",Upper,\"%\\n\\n\",sep=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final thoughts\n",
    "As seen by the report at 95% confidence interval we cannot reject the null hypothesis, therefore, we do not observe a significant lift in Positive Response Rate if we use a level of confidence of 95%. Contrary to this, we initially concluded there was a significant increment within the default output from Lift Measurement Tool.\n",
    "\n",
    "Opinions may vary as to which confidence interval is acceptable for Brand Lift or any other Marketing Study and most likely will depend on the goal, but ultimately, decision should be on the marketeer. In most studies, this situation is usually addressed by providing the p-value which allows the reader to define its tolerance on accepting or rejecting the hypothesis.\n",
    "\n",
    "## Feedback\n",
    "What's your thought on this? What levels of significance to you use in marketing studies? Is it something you consider relevant?\n",
    "\n",
    "https://www.linkedin.com/in/crisandrews/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
